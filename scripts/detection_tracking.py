# -*- coding: utf-8 -*-

import core.test_engine as infer_engine
from core.config import cfg
from core.config import merge_cfg_from_file
from core.config import assert_and_infer_cfg
import cv2
import utils.c2 as c2_utils
import numpy as np
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from mobilityaids_detector.msg import Detection, Detections
from sensor_msgs.msg import CameraInfo
from visualization_msgs.msg import Marker, MarkerArray

class Detector:
    def __init__(self):
        weights_file = "/home/kollmitz/tools/detectron_depth/trained_models/googlenet_xxs_RGB_hospital/train/hospital_train_RGB_Depth/generalized_rcnn/model_final.pkl"
        config_file = "/home/kollmitz/tools/detectron_depth/configs/hospital_detection/faster_rcnn_googlenet_xxs_RGB.yaml"
        merge_cfg_from_file(config_file)
        cfg.TEST.WEIGHTS = weights_file
        cfg.NUM_GPUS = 1
    
        assert_and_infer_cfg()
        self.model = infer_engine.initialize_model_from_cfg()
        self.bridge = CvBridge()
    
        rospy.Subscriber("/kinect2/qhd/image_color_rect", Image, self.image_callback) 
        rospy.Subscriber("/kinect2/qhd/camera_info", CameraInfo, self.cam_info_callback)
        
        self.image_viz_pub = rospy.Publisher("mobility_aids/image", Image)
        self.rviz_viz_pub = rospy.Publisher("mobility_aids/vis", MarkerArray)
        self.det_pub = rospy.Publisher("mobility_aids/detections", Detections)
        
        self.last_image = None
        self.new_image = False
        
        self.camera_info = None
        self.classnames = ["background", "pedestrian", "crutches", "walking_frame", "wheelchair", "push_wheelchair"]

    def convert_from_cls_format(self, cls_boxes, cls_depths):
        """Convert from the class boxes/segms/keyps format generated by the testing
        code.
        """
        box_list = [b for b in cls_boxes if len(b) > 0]
        if len(box_list) > 0:
            boxes = np.concatenate(box_list)
        else:
            boxes = None
        if cls_depths is not None:
            depth_list = [b for b in cls_depths if len(b) > 0]
            if len(depth_list) > 0:
                depths = np.concatenate(depth_list)
            else:
                depths = None
        else:
            depths = None
        classes = []
        for j in range(len(cls_boxes)):
            classes += [j] * len(cls_boxes[j])
        return boxes, depths, classes
    
    def get_world_position(self, im_x, im_y, depth):
        
        if self.camera_info is not None:
            #camera calibration
            fx = self.camera_info.K[0]
            cx = self.camera_info.K[2]
            fy = self.camera_info.K[4]
            cy = self.camera_info.K[5]
            
            image_height = self.camera_info.height
            
            x = (im_x - cx)/fx * depth
            y = (image_height - im_y - cy)/fy * depth
            z = depth
            
            return x,y,z
    
    def get_detection(self, bbox, confidence, depth, category):
        
        im_x = (bbox[0]+bbox[2])/2
        im_y = (bbox[1]+bbox[3])/2
        
        
        x,y,z = self.get_world_position(im_x, im_y, depth)
        
        det = Detection()
        det.category = self.classnames[category]
        det.track_id = 0
        det.position.x = x
        det.position.y = y
        det.position.z = z
        det.confidence = confidence
        
        return det
    
    def get_marker(self, header, position, color, marker_id):
        
        marker = Marker()
        marker.header = header
        marker.id = marker_id
        marker.ns = "mobility_aids"
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        marker.pose.position = position
        marker.color.b = float(color[0])/255
        marker.color.g = float(color[1])/255
        marker.color.r = float(color[2])/255
        marker.color.a = 1.0
        marker.scale.x = 0.5
        marker.scale.y = 0.5
        marker.scale.z = 0.5
        marker.pose.orientation.w = 1
        marker.lifetime = rospy.Duration()
        
        return marker
    
    def delete_last_markers(self):
        delete_marker = Marker()
        delete_markers = MarkerArray()
        delete_marker.action = Marker.DELETEALL
        delete_markers.markers.append(delete_marker)
        
        self.rviz_viz_pub.publish(delete_markers)
    
    def process_detections(self, image, cls_boxes, cls_depths, thresh = 0.9):
        
        dets = Detections()
        dets.header = self.last_image.header
        
        markers = MarkerArray()
        
        boxes, depths, classes = self.convert_from_cls_format(cls_boxes, cls_depths)
        
        # one threshold per class
        if isinstance(thresh, float):
            thresh = thresh * np.ones(cfg.MODEL.NUM_CLASSES)
        
        #{'person'}    {'crutches'}    {'walking_frame'}    {'wheelchair'}    {'push_wheelchair'}
        colors_box = [[1, 1, 1],
                      [39,167,0],
                      [0,0,191],
                      [0,255,255],
                      [26,126,26],
                      [101,0,255]]
        
        for i in range(len(classes)):
            bbox = boxes[i, :4]
            score = boxes[i, -1]
            cla = classes[i]
            depth = depths[i]
            
            if score > thresh[cla]:
                # draw bbox
                color_box = colors_box[cla]
                cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color_box, 3)
                
                # fill detections message
                det = self.get_detection(bbox, score, depth, cla)
                
                marker = self.get_marker(self.last_image.header, det.position, colors_box[cla], i)
                
                dets.detections.append(det)
                markers.markers.append(marker)
                
        self.det_pub.publish(dets)
        self.image_viz_pub.publish(self.bridge.cv2_to_imgmsg(image, encoding="passthrough"))
        
        self.delete_last_markers()
        self.rviz_viz_pub.publish(markers)
    
    def process_last_image(self):
        
        if self.new_image:
            image = self.bridge.imgmsg_to_cv2(self.last_image, "passthrough")
            with c2_utils.NamedCudaScope(0):
                cls_boxes, cls_depths, cls_segms, cls_keyps = infer_engine.im_detect_all(
                    self.model, image, None)
            
            self.process_detections(image, cls_boxes, cls_depths)
            self.new_image = False

    def cam_info_callback(self, data):
        
        if self.camera_info is None:
            print "camera info received"
            self.camera_info = data

    def image_callback(self, image):
        
        if self.camera_info is not None:
            try:
                self.last_image = image
                self.new_image = True
                
            except CvBridgeError as e:
                print(e)
                return

def main(args):
    
    rospy.init_node('detector', anonymous=True)
    det = Detector();
    
    print "waiting for images ..."
    rate = rospy.Rate(30)
    
    while not rospy.is_shutdown():
        det.process_last_image()
        rate.sleep()
    
    print "done"
    
if __name__ == '__main__':
    main(None)